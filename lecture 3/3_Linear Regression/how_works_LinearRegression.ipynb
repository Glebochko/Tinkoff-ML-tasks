{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как внутри работет линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ЧТО делает линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте положим в X какие-то трехмерные векторы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 7],\n",
    "              [1, 2, 6],\n",
    "              [2, 2, 10],\n",
    "              [2, 3, 11],\n",
    "              [10, 5, 2],\n",
    "              [14, 3, 6],\n",
    "              [20, 3, 50]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим $y$ по такой формуле:\n",
    "\n",
    "$$y = 100x - 200y + 70z + 35 + \\varepsilon$$\n",
    "\n",
    "Где $\\varepsilon$ - это какой-то шум с нормальным распределением с дисперсией 10, чтобы линейная формула не была уж совсем точной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 421.96877641,  153.68680504,  526.13606001,  416.93016021,\n",
       "        176.10255873, 1257.25313897, 4920.40497129])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.dot(X, np.array([100, -200, 70])) + 35 + np.random.normal(0, 10, len(X))\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим на этих данных линейную регрессию и посмотрим, сможет ли она восстановить параметры модели $100, 200, 70, 35$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  99.61628956, -197.22486226,   69.78969342])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = model.coef_\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.18408298468239"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const = model.intercept_\n",
    "const"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И внезапно линейная регрессия как-то примерно угадала наши коэффициенты! Примерно, потому что мы добавили шум.\n",
    "\n",
    "Как она это делает? Сейчас узнаем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## КАК работает линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сути мы хотим подобрать числа $a_0, a_1, a_2, a_3$ для вот такой модели:\n",
    "\n",
    "$$f(x_1, x_2, x_3) = a_0 + a_1 x_1 + a_2 x_2 + a_3 x_3$$\n",
    "\n",
    "Мы хотим подобрать их так, чтобы функция потерь на наших данных была минимальна. В LinearRegression используют функцию потерь MSE - сумму квадратов отклонений от настоящего значения.\n",
    "\n",
    "То есть задача такая:\n",
    "\n",
    "$$\\sum\\limits_{i=1}^{n}(f(x_{i1}, x_{i2}, x_{i3}) - y_i)^2 \\rightarrow \\min$$\n",
    "\n",
    "\n",
    "$$\\sum\\limits_{i=1}^{n}(a_0 + a_1 x_{i1} + a_2 x_{i2} + a_3 x_{i3} - y_i)^2 \\rightarrow \\min$$\n",
    "\n",
    "Где n - это количество входных данных. Давайте рассмотрим эту сумму как функцию от 4 переменных $a_0, a_1, a_2, a_3$, которую нам нужно минимизировать. А числа $x_{ij}$ и $y_i$, получается, будут обычными константами.\n",
    "\n",
    "$$MSE(a_0, a_1, a_2, a_3) \\rightarrow \\min$$\n",
    "\n",
    "Давайте посчитаем частную производную по каждой координате.\n",
    "\n",
    "Начнем с координаты $a_1$.\n",
    "\n",
    "$$MSE'_{a_1}(a_0, a_1, a_2, a_3) = \\sum\\limits_{i=1}^{n}((a_0 + a_1 x_{i1} + a_2 x_{i2} + a_3 x_{i3} - y_i)^2)'_{a_1}=$$\n",
    "\n",
    "Раскрываем квадрат, вынося отдельно члены, которые делятся на $a_1^2$, $a_1$ и $1$.\n",
    "\n",
    "$$= \\sum\\limits_{i=1}^{n}(x_{i1}^2a_1^2 + 2x_{i1}(a_0 + a_2 x_{i2} + a_3 x_{i3} - y_i)a_1 + (a_0 + a_2 x_{i2} + a_3 x_{i3} - y_i)^2)'_{a_1}=$$\n",
    "\n",
    "Считаем производную, одна из скобок при этом обнуляется:\n",
    "\n",
    "$$= \\sum\\limits_{i=1}^{n}(2x_{i1}^2a_1 + 2x_{i1}(a_0 + a_2 x_{i2} + a_3 x_{i3} - y_i))=$$\n",
    "\n",
    "Теперь вынесем $2$ и $x_{i1}$\n",
    "\n",
    "$$= 2\\sum\\limits_{i=1}^{n}(x_{i1}a_1 + a_0 + a_2 x_{i2} + a_3 x_{i3} - y_i)x_{i1}=$$\n",
    "\n",
    "Заметим, что в скобках получилось очень простое выражение!\n",
    "\n",
    "$$= 2\\sum\\limits_{i=1}^{n}(f(x_{i1}, x_{i2}, x_{i3}) - y_i)x_{i1}$$\n",
    "\n",
    "Давайте приравняем все 4 производные (по $a_0, a_1, a_2, a_3$) нулю, тогда:\n",
    "\n",
    "$$\\sum\\limits_{i=1}^{n}(a_0 + a_1 x_{i1} + a_2 x_{i2} + a_3 x_{i3} - y_i) = 0$$\n",
    "$$\\sum\\limits_{i=1}^{n}(a_0 + a_1 x_{i1} + a_2 x_{i2} + a_3 x_{i3} - y_i)x_{i1} = 0$$\n",
    "$$\\sum\\limits_{i=1}^{n}(a_0 + a_1 x_{i1} + a_2 x_{i2} + a_3 x_{i3} - y_i)x_{i2} = 0$$\n",
    "$$\\sum\\limits_{i=1}^{n}(a_0 + a_1 x_{i1} + a_2 x_{i2} + a_3 x_{i3} - y_i)x_{i3} = 0$$\n",
    "\n",
    "Давайте сгруппируем все выражения по $a_0, a_1, a_2, a_3$:\n",
    "\n",
    "$$na_0 + (\\sum\\limits_{i=1}^{n}x_{i1})a_1 + (\\sum\\limits_{i=1}^{n}x_{i2})a_2 + (\\sum\\limits_{i=1}^{n}x_{i3})a_3= \\sum\\limits_{i=1}^{n}y_i$$\n",
    "\n",
    "$$(\\sum\\limits_{i=1}^{n}x_{i1})a_0 + (\\sum\\limits_{i=1}^{n}x_{i1}^2)a_1 + (\\sum\\limits_{i=1}^{n}x_{i1}x_{i2})a_2 + (\\sum\\limits_{i=1}^{n}x_{i1}x_{i3})a_3= \\sum\\limits_{i=1}^{n}x_{i1}y_i$$\n",
    "\n",
    "$$(\\sum\\limits_{i=1}^{n}x_{i2})a_0 + (\\sum\\limits_{i=1}^{n}x_{i1}x_{i2})a_1 + (\\sum\\limits_{i=1}^{n}x_{i2}^2)a_2 + (\\sum\\limits_{i=1}^{n}x_{i2}x_{i3})a_3= \\sum\\limits_{i=1}^{n}x_{i2}y_i$$\n",
    "\n",
    "$$(\\sum\\limits_{i=1}^{n}x_{i3})a_0 + (\\sum\\limits_{i=1}^{n}x_{i1}x_{i3})a_1 + (\\sum\\limits_{i=1}^{n}x_{i2}x_{i3})a_2 + (\\sum\\limits_{i=1}^{n}x_{i3}^2)a_3= \\sum\\limits_{i=1}^{n}x_{i3}y_i$$\n",
    "\n",
    "Ура, мы получили красивую симметричную систему уравнения, 4 уравнения, 4 неизвестных. Если определитель матрицы коэффициентов не равен нулю, то у него есть ровно одно решение, и его мы умеем находить (методом Гаусса, например). Если определитель вдруг стал равен нулю, то решений либо 0, либо бесконечно.\n",
    "\n",
    "У непрерывно-дифференцируемой функции, которая при стремлении по каждой координате к плюс или минус бесконечности сама стремится к плюс бесконечности, всегда существует глобальный минимум. В точке глобального минимума все производные как раз равны нулю. Следовательно, существует всегда хотя бы одно решение, и мы его найдем."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
