{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML T-Generation Занятие 4: Классификация.\n",
    "# Логрегрессия. KNN. Метрики.\n",
    "\n",
    "Автор: Гаркавый Андрей (andrewgarkavyy@gmail.com)\n",
    "\n",
    "\n",
    "## 0. План\n",
    "\n",
    "1. Логистическая регрессия: теория\n",
    "\n",
    "2. Логистическая регрессия: практика \n",
    "\n",
    "3. Сравнение с KNN\n",
    "\n",
    "3. Precision/Recall\n",
    "\n",
    "4. ROC-AUC\n",
    "\n",
    "5. Небинарная классификация\n",
    "\n",
    "## 1. Логистическая регрессия: теория\n",
    "(в названии регрессия, но на самом деле это алгоритм классификации)\n",
    "\n",
    "\n",
    "Рассмотрим **задачу классификации**. Для простоты рассматрим бинарную классификацию: для каждого примера в обучающей выборке указан его класс: 0 или 1.\n",
    "\n",
    "Нам нужно по признакам научиться восстанавливать класс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы уже умеем предсказывать числа (решать задачу регрессии) с помощью модели Линейной регрессии. Самое простое - использовать её для предсказания классов? А именно, будем просто предсказывать эти 0 и 1.\n",
    "\n",
    "Тут даже понятно, как решать по предсказанному числу, какой это класс - если больше 0.5, то класс 1, иначе класс 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот подход работает, но он несколько противоестественный: предположим, наша модель предсказала для объекта класса 1 значение 2. За такое предсказание она получит такой же штраф, как за предсказание 0: $(2-1)^2 = (0-1)^2$.\n",
    "\n",
    "Давайте попробуем придумать более естественную функцию потерь. Естественно считать, что чем больше предсказание нашей модели, тем сильнее она уверена, что объект принадлежит классу 1. Давайте попробуем интерпретировать предсказание модели как вероятность того, что объект принадлежит классу 1.\n",
    "\n",
    "Модель (теоретически) может выдавать значения от минус до плюс бесконечности, значит нам нужно научиться превращать интервал $(-\\infty, \\infty)$ в интервал $(0, 1)$. Такие функции называют сигмоидами -- потому что они напоминают внешне букву s. Наиболее стандартная такая функция называется логистической функцией и выглядит так:\n",
    "$$\n",
    " \\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сигмоидная функция\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10eab1da0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-5, 5, 100)\n",
    "plt.plot(x, sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, можно считать, что если наша модель предсказывает для объекта $x$ число $f(x)$ это означает, что $p_x$ = $\\sigma(f(x))$ - вероятность того, что объект принадлежит к классу 1.\n",
    "\n",
    "Для данного примера класса 1 вероятность того, что наша модель угадала правльно равна $p_x$, для примера класса 0 эта вероятность равна $1-p_x$. \n",
    "\n",
    "Давайте посчитаем вероятность того, что наша модель \"угадает\" значение всех элементов:\n",
    "\n",
    "$$\\prod_{x \\in 1} p_x \\prod_{x \\in 0} (1-p_x)$$\n",
    "\n",
    "Мы хотим максимизировать эту вероятность.\n",
    "\n",
    "Работать с произведением неудобно, поэтому возьмем логарифм:\n",
    "\n",
    "$$\\sum_{x \\in 1} \\ln(p_x)  + \\sum_{x \\in 0} \\ln(1-p_x)$$\n",
    "\n",
    "Из этого бы получилась отличная функция потерь, вот только функцию потерь мы хотим минимизировать, а эту функцию нужно максимизировать для лучшего результата. Поэтому умножим её на минус один.\n",
    "\n",
    "$$Logloss = -\\sum_{x \\in 1} \\ln(p_x)  - \\sum_{x \\in 0} \\ln(1-p_x)$$\n",
    "\n",
    "Эта функция потерь называется Logloss. Оказывается, что её довольно просто оптимизировать.\n",
    "\n",
    "Описанный нами алгоритм называется **Логистическая регрессия**. Это алгоритм бинарной классификации (а не регрессии, пусть название вас не путает):\n",
    "\n",
    "1) алгоритм предсказывает $f(x)$ по модели линейной регрессии ($f(x) = a_0 + a_1 x_1 + \\ldots a_n x_n$)\n",
    "\n",
    "2) от каждого значения считается сигмоида для предсказания вероятности ($p_x = \\sigma(f(x)) = \\frac{1}{1 + e^{f(x)}}$)\n",
    "\n",
    "3) по этим вероятностям считается Logloss ($Logloss = -\\sum_{x \\in 1} \\ln(p_x)  - \\sum_{x \\in 0} \\ln(1-p_x)$)\n",
    "\n",
    "4) параметры для модели подбираются так, чтобы именно этот логлосс и был минимален\n",
    "\n",
    "5) предсказание после этого делается так: если вероятность больше 0.5 (то есть f(x) > 0), то это класс 1, иначе это класс 0.\n",
    "\n",
    "Можно также представить, что вы пытаетесь разделить точки двух разных цветов с помощью плоскости. Все, точки оказавшиеся в одном полупространстве, вы предсказываете как класс 0, а в другом - как класс 1.\n",
    "\n",
    "# 2. Логистическая регрессия: практика\n",
    "\n",
    "Как обычно, эта модель уже есть в библиотеке sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем работать с датасетом, содержащим данные о порядка 18 тысячах звезд, некоторые из которых являются пульсарами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('pulsar_stars.csv')\n",
    "\n",
    "X = data.drop(columns=['target_class']) # убираем столбец с целевой переменной\n",
    "y = data['target_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean of the integrated profile</th>\n",
       "      <th>Standard deviation of the integrated profile</th>\n",
       "      <th>Excess kurtosis of the integrated profile</th>\n",
       "      <th>Skewness of the integrated profile</th>\n",
       "      <th>Mean of the DM-SNR curve</th>\n",
       "      <th>Standard deviation of the DM-SNR curve</th>\n",
       "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
       "      <th>Skewness of the DM-SNR curve</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140.562500</td>\n",
       "      <td>55.683782</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-0.699648</td>\n",
       "      <td>3.199833</td>\n",
       "      <td>19.110426</td>\n",
       "      <td>7.975532</td>\n",
       "      <td>74.242225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.507812</td>\n",
       "      <td>58.882430</td>\n",
       "      <td>0.465318</td>\n",
       "      <td>-0.515088</td>\n",
       "      <td>1.677258</td>\n",
       "      <td>14.860146</td>\n",
       "      <td>10.576487</td>\n",
       "      <td>127.393580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.015625</td>\n",
       "      <td>39.341649</td>\n",
       "      <td>0.323328</td>\n",
       "      <td>1.051164</td>\n",
       "      <td>3.121237</td>\n",
       "      <td>21.744669</td>\n",
       "      <td>7.735822</td>\n",
       "      <td>63.171909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.750000</td>\n",
       "      <td>57.178449</td>\n",
       "      <td>-0.068415</td>\n",
       "      <td>-0.636238</td>\n",
       "      <td>3.642977</td>\n",
       "      <td>20.959280</td>\n",
       "      <td>6.896499</td>\n",
       "      <td>53.593661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.726562</td>\n",
       "      <td>40.672225</td>\n",
       "      <td>0.600866</td>\n",
       "      <td>1.123492</td>\n",
       "      <td>1.178930</td>\n",
       "      <td>11.468720</td>\n",
       "      <td>14.269573</td>\n",
       "      <td>252.567306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mean of the integrated profile  \\\n",
       "0                       140.562500   \n",
       "1                       102.507812   \n",
       "2                       103.015625   \n",
       "3                       136.750000   \n",
       "4                        88.726562   \n",
       "\n",
       "    Standard deviation of the integrated profile  \\\n",
       "0                                      55.683782   \n",
       "1                                      58.882430   \n",
       "2                                      39.341649   \n",
       "3                                      57.178449   \n",
       "4                                      40.672225   \n",
       "\n",
       "    Excess kurtosis of the integrated profile  \\\n",
       "0                                   -0.234571   \n",
       "1                                    0.465318   \n",
       "2                                    0.323328   \n",
       "3                                   -0.068415   \n",
       "4                                    0.600866   \n",
       "\n",
       "    Skewness of the integrated profile   Mean of the DM-SNR curve  \\\n",
       "0                            -0.699648                   3.199833   \n",
       "1                            -0.515088                   1.677258   \n",
       "2                             1.051164                   3.121237   \n",
       "3                            -0.636238                   3.642977   \n",
       "4                             1.123492                   1.178930   \n",
       "\n",
       "    Standard deviation of the DM-SNR curve  \\\n",
       "0                                19.110426   \n",
       "1                                14.860146   \n",
       "2                                21.744669   \n",
       "3                                20.959280   \n",
       "4                                11.468720   \n",
       "\n",
       "    Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve  \\\n",
       "0                              7.975532                      74.242225   \n",
       "1                             10.576487                     127.393580   \n",
       "2                              7.735822                      63.171909   \n",
       "3                              6.896499                      53.593661   \n",
       "4                             14.269573                     252.567306   \n",
       "\n",
       "   target_class  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как обычно, разбиваем данные на тренировочную и тестовую части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели классификации происходит ровно так же, как и модели регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на первый параметр $С$ - он отвечает за регуляризацию: меньшие значения $С$ соответствуют большим штрафам за \"усложнение\" модели.\n",
    "\n",
    "Предсказание происходит тоже ровно так же: получаем целевую функцию (класс) по методу predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = log_reg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но в отличие от регрессии у моделей классификации часто есть еще и возможность предсказать вероятность принадлежности классу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99380878, 0.00619122],\n",
       "       [0.28741592, 0.71258408],\n",
       "       [0.98287336, 0.01712664],\n",
       "       ...,\n",
       "       [0.99790465, 0.00209535],\n",
       "       [0.99366324, 0.00633676],\n",
       "       [0.97400367, 0.02599633]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = log_reg.predict_proba(X_test) #probability = вероятность\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Сравнение с KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как понять, хороший ли получился результат? Самое простое - сделать как в регрессии, сравнить используемую метрику на нашей модели и на какой-нибудь другой. Давайте возьмем три модели:\n",
    "\n",
    "1) Предсказать всем 0 (все равно звезда почти всегда не пульсар)\n",
    "\n",
    "2) Лог. регрессия\n",
    "\n",
    "3) KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 11375, 1: 1153})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оказывается, звезда в 10 раз чаще не пульсар, чем пульсар (по крайней мере в нашем датасете)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_const = np.zeros(len(X_test)) \n",
    "y_pred_proba_const = y_pred_const\n",
    "y_pred_proba_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00619122, 0.71258408, 0.01712664, ..., 0.00209535, 0.00633676,\n",
       "       0.02599633])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "y_pred_proba_log_reg = log_reg.predict_proba(X_test)[:, 1]  # оставили только второй столбец\n",
    "y_pred_proba_log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось обучить модель KNN. Вы уже ее писали ее на первом занятии, но давайте вспомним, что это за алгоритм классификации.\n",
    "\n",
    "**Метод K ближайших соседей (K Nearest Neighbors)** заключается в том, что мы рассматриваем каждый объект как точку в $n$-мерном пространстве, где $n$ - это число признаков. Тогда чтобы предсказать класс какой-нибудь новой точки, нам нужно просто найти $K$ ближайших к ней объектов в тренировочной части и выбрать самый популярный класс среди них.\n",
    "\n",
    "Естественно, эта модель тоже уже написана в sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5) # выберем K=5 например\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0. , 0. ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_proba_knn = knn.predict_proba(X_test)[:, 1]  # оставили только второй столбец\n",
    "y_pred_proba_knn[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот алгоритм не заточен под предсказание вероятности принадлежности к классу, и делает это очень наивно и грубо: если среди $K$ соседей ровно $T$ принадлежат классу 1, то вероятность принадлежности классу 1 равна $\\frac{T}{K}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь осталось сравнить наши предсказанные результаты. Например, раз мы учили лог. регрессию на logloss, давайте сравним его (помните, для регрессии же мы сравнивали MSE).\n",
    "\n",
    "**Обязательное задание 1**: реализуйте logloss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуйте функцию\n",
    "# Как обычно, чем короче, тем лучше\n",
    "\n",
    "def logloss(y_real, y_pred_proba):\n",
    "    return - np.sum(np.log(1 - np.abs(y_real - y_pred_proba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss = 2.384229082034556\n",
      "Real answer = 2.384229082034556\n"
     ]
    }
   ],
   "source": [
    "# Тест:\n",
    "print('Logloss =', logloss(np.array([0, 1, 0, 1, 0]), np.array([0.2, 0.8, 0.4, 0.6, 0.6])))\n",
    "print('Real answer =', -(np.log(0.8) + np.log(0.8) + np.log(0.6) + np.log(0.6) + np.log(0.4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, чему равен лог лосс на разных моделях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss(y_test, y_pred_proba_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша модель \"все вероятности равны 0\" не работает: если мы угадали все классы, то мы действительно получаем логлосс 0. Но если мы хотя бы раз ошиблись, то мы получим минус логарифм от 0, то есть бесконечность. Предсказывать вероятность в логлоссе как прямо 0 никогда нельзя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413.18283550680894"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss(y_test, y_pred_proba_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss(y_test, y_pred_proba_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С KNN получилась такая же проблема: слишком много вероятностей, равных 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, Logloss так себе подходит для сравнения результатов классификации - у наивных моделей там часто возникают бесконечности, да и само число ничего конкретного не значит. В MSE мы хотя бы примерно понимали, что такое средний квадрат отклонений, а тут это абсолютно не говорящее ни о чем число."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте лучше посчитаем **точность** - accuracy. То есть просто **долю объектов с правильно предсказанным классом**.\n",
    "\n",
    "(вообще называеть ее \"точность\" - плохая идея, потому что у другой метрики, которую мы сегодня рассмотрим (precision) на русский ровно тот же перевод)\n",
    "\n",
    "**Обязательное задание 2:** реализуйте функцию accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуйте функцию\n",
    "# Как обычно, чем короче, тем лучше\n",
    "\n",
    "def accuracy(y_real, y_pred):\n",
    "    return np.mean(y_real == y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6\n",
      "Real answer = 0.6\n"
     ]
    }
   ],
   "source": [
    "# Тест:\n",
    "print('Accuracy =', accuracy(np.array([0, 1, 0, 1, 0]), np.array([0, 0, 0, 1, 1])))\n",
    "print('Real answer =', 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, чему равна accuracy на разных моделях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9094972067039107"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_test, y_pred_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9789571694599628"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_test, y_pred_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733705772811918"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_test, y_pred_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы явно видим, что точность константного предсказания (все звезды - не пульсары) - это уже 90%. Действительно, в тестовой части тоже каждая только примерно 10-я звезда является пульсаром.\n",
    "\n",
    "Причем точности и Лог. регрессии, и KNN - значительно выше, это чуть больше 97%. На конкретно моем разбиении на train и test получилось, что accuracy у лог. регрессии все-таки лучше, но пока неясно, это погрешность и разницы особое нет, или все-таки есть значительнон преимущество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь сразу видна большая проблема: из-за несбалансированности классов (9 к 1) accuracy наивного предсказания легко набирает сразу 90%. Очень тяжело сравнивать модели по метрике, которая у всех нормальных моделей находится на маленьком отрезке $[0.9, 1.0]$. А представьте, что пульсаров было бы еще меньше: один из сотни звезд. А такое в жизни бывает очень часто - например в рекламе вам нужно понять, сделает ли юзер клик по этому баннеру, и этих кликов по баннеру в данных встречается очень и очень мало, обычно все-таки клика нет. Поэтому модель \"всегда нет клика\" будет сразу набирать 99% accuracy.\n",
    "\n",
    "Для таких дико несбалансированных данных нужны какие-то другие, более говорящие метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Precision / Recall\n",
    "\n",
    "Чтобы обойти эту проблему часто рассматривают две другие метрики: **precision** (точность) и **recall** (полнота). Пусть у нас все еще бинарная классификация, и класса 0 очень много, а вот класса 1 - поменьше.\n",
    "\n",
    "Точность -- доля объектов класса 1 среди всех объектов, которые наш классификатор отнес к классу 1.\n",
    "\n",
    "Полнота -- доля объектов класса 1, которые наш классификатор определил правильно среди всех объектов класса 1:\n",
    "\n",
    "**Обязательное задание 3:** реализовать две эти функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуйте функцию\n",
    "# Как обычно, чем короче, тем лучше\n",
    "\n",
    "def precision(y_real, y_pred):\n",
    "    return (np.mean(y_real[y_pred == 1]))\n",
    "\n",
    "def recall(y_real, y_pred):\n",
    "    return np.mean(y_pred[y_real == 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(np.array([0, 1, 0, 1, 0]), np.array([1, 1, 0, 1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(precision(y_test, y_pred_const))\n",
    "print(recall(y_test, y_pred_const))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9429928741092637\n",
      "0.8168724279835391\n"
     ]
    }
   ],
   "source": [
    "print(precision(y_test, y_pred_log_reg))\n",
    "print(recall(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9054373522458629\n",
      "0.7880658436213992\n"
     ]
    }
   ],
   "source": [
    "print(precision(y_test, y_pred_knn))\n",
    "print(recall(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие мы получили результаты? \n",
    "\n",
    "1) Константное предсказание \"всегда говори 0\" получает nan точность (это доля пульсаров среди предсказанных пульсаров, а мы ни один решили не предсказывать) и 0 полноту (это доля пульсаров, которые мы нашли, а мы ничего не нашли).\n",
    "\n",
    "2) Среди предсказанных с помощью KNN и Лог. регрессии пульсаров 90%-94% звезд действительно являются пульсарами.\n",
    "\n",
    "3) А вот среди всех пульсаров наши модели нашли только 78%-80% пульсаров.\n",
    "\n",
    "4) В целом получается, что модели предсказывают пульсары скорее точно, но при этом много еще не находят (точность больше полноты)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто для того, чтобы учесть несбалансированность нашего множества, мы можем задать разный вес для разных классов. \n",
    "Например, у Лог. регрессии есть параметр class_weight, который принимает словарь, сопоставляющий каждому классу его вес.\n",
    "\n",
    "При этос вес участвует в Логлоссе - каждое слагаемое с реальным классом 1 просто умножается на вес класса 1, а слагаемое с реальным классом 0 просто умножается на вес класса 0.\n",
    "\n",
    "По сути эти веса значат то, насколько важнее предсказать хорошо класс 0 или класс 1.\n",
    "\n",
    "$$Logloss = -w_1 \\sum_{x \\in 1} \\ln(p_x)  -w_0 \\sum_{x \\in 0} \\ln(1-p_x)$$\n",
    "\n",
    "В изначальных данных у нас почти все звезды были пульсарами (класса 0), и их качество предсказания было гораздо важнее, давайте сбалансируем веса (так половина веса будет приходить из обычных звезд и половина веса из пульсаров)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_w = LogisticRegression(class_weight = {0: 1, 1: 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight={0: 1, 1: 10}, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_w.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_w = log_reg_w.predict(X_test)\n",
    "y_pred_proba_w = log_reg_w.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7725694444444444\n",
      "0.9156378600823045\n"
     ]
    }
   ],
   "source": [
    "print(precision(y_test, y_pred_w))\n",
    "print(recall(y_test, y_pred_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность классификатора заметно упала -- он стал чаще говорить \"1\" (так как ошибиться с непульсаром теперь не так страшно), но зато заметно возросла полнота. Хорошо это или плохо -- зависит от того, как мы собираемся использовать наш классификатор.\n",
    "\n",
    "Если для нас очень важно не пропустить ни одного пульсара (а если мы какую-то звезду тоже назовем пульсаром по ошибке, то не очень страшно) нам нужно растить полноту -- это возможно, например, если потом на выбранные звезды посмотрят в радиотелескоп и уточнят предсказание.\n",
    "\n",
    "А может быть, что для нас важно не назвать пульсаром звезду, которая им не является (например, ко всем потенциальным пульсарам мы отправим дорогой исследовательский зонд -- не страшно пропустить какие-то, но очень обидно отправить зонд к не-пульсару).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для полноты картины введем еще два определения:\n",
    "    - ошибка первого рода (Type I error, false positive) - ситуация, когда наша модель отнесла объект класса 0 к классу 1\n",
    "    - ошибка второго рода (Type II error, false negative) - ситуация, когда наша модель отнесла объект класса 1 к классу 0\n",
    "    \n",
    "Аналогично правильные предсказания можно разделить на true positives и true negatives\n",
    "\n",
    "![Таблица](table.jpg)\n",
    "\n",
    "Как запомнить какая ошибка что: в сказке про мальчика, который кричал \"Волк!\" сначала описывается ошибка первого рода, а потом - второго.\n",
    "\n",
    "![Ошибки](errors.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обязательно задание 4:** запишите accuracy, precision и recall в терминах количества ошибок первого и второго рода (FP и FN) и количества правильных предсказаний (TP, TN).\n",
    "\n",
    "Accuracy = <..>\n",
    "\n",
    "Precision = <..>\n",
    "\n",
    "Recall = <..>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обязательное задание 5:** постройте график зависимости precision и recall от соотношения весов в графе в логистической регрессии.\n",
    "\n",
    "Пусть вес класса 0 будет всегда равен 1, переберите чему равен вес класса 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# постройте график\n",
    "for weight in range(1, 15) :\n",
    "    mylgw = LogisticRegression(class_weight = {0: 1, 1: weight})\n",
    "    mylgw.fit(X_train, y_train)\n",
    "    my_y_pred = mylgw.predict(X_test)\n",
    "    \n",
    "    plt.scatter(weight, precision(y_test, my_y_pred), color='r')\n",
    "    plt.scatter(weight, recall(y_test, my_y_pred), color='b')\n",
    "    \n",
    "plt.xlabel('Weight') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует метрика, объединяющая точность и полноту - их среднее гармоническое. Эта метрика называется $F_1$-мерой:\n",
    "\n",
    "$$ F_1 = \\frac{2* precision*recall}{precision+recall}$$\n",
    "\n",
    "**Обязательное задание 6:** добавьте на график еще и f1-меру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# постройте график\n",
    "def F1(precision, recall) :\n",
    "    return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "\n",
    "for weight in range(1, 15) :\n",
    "    mylgw = LogisticRegression(class_weight = {0: 1, 1: weight})\n",
    "    mylgw.fit(X_train, y_train)\n",
    "    my_y_pred = mylgw.predict(X_test)\n",
    "    \n",
    "    plt.scatter(weight, precision(y_test, my_y_pred), color='r')\n",
    "    plt.scatter(weight, recall(y_test, my_y_pred), color='b')\n",
    "    plt.scatter(weight, F1(precision(y_test, my_y_pred), recall(y_test, my_y_pred)), color='g')\n",
    "    \n",
    "plt.xlabel('Weight') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ROC-AUC\n",
    "\n",
    "Продолжим изучать метрики бинарной классификации. Представим, что мы предсказали пульсары - но изучать их надо в каком-то порядке. В порядке уменьшения вероятности, что они пульсары.\n",
    "\n",
    "Надо как-то научить мерить, **насколько хорошо мы предсказали вероятности с точки зрения порядка**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте отсортируем все зведы по вероятности, что они пульсары. Если бы мы идеально предсказали пульсары, то сначала в этом списке идут исключительно не-пульсары, а потом исключительно пульсары.\n",
    "\n",
    "В реальности, конечно, там будут ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00616507, 0.72770764, 0.01724088, ..., 0.00216983, 0.00603648,\n",
       "       0.0249366 ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15985, 0.0061650695872782595),\n",
       " (8188, 0.7277076442100362),\n",
       " (8157, 0.01724088449991814),\n",
       " (2589, 0.4509435795509389),\n",
       " (11909, 0.0180991253333306)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(X_test.index, y_pred_proba))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13504, 1.3472657690546938e-08),\n",
       " (14049, 1.5596482822803753e-08),\n",
       " (16272, 2.7498355087642876e-08),\n",
       " (9529, 3.073894326442622e-08),\n",
       " (7472, 3.6882374279609234e-08)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_by_proba = sorted(list(zip(X_test.index, y_pred_proba)), key=lambda x: x[1])\n",
    "sorted_by_proba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "results = [y_test[id] for id, proba in sorted_by_proba]\n",
    "print(results[:25])\n",
    "print(results[1000:1025])\n",
    "print(results[3000:3025])\n",
    "print(results[5000:5025])\n",
    "print(results[-25:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот мы отсортировали по вероятности принадлежности классу 1 - и действительно, сначала долго идут объекты класса 0, потом в какой-то момент начинают появляться пульсары, потом их все больше, и в конце остаются исключительно они (ну почему-то кроме последнего в моем случае).\n",
    "\n",
    "Датасайентисты очень любят рисовать ROС-кривую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "plt.figure(figsize=(7, 7))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.plot(fpr, tpr, 'b', linewidth=3)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot([0, 0], [0, 1], 'k')\n",
    "plt.plot([1, 1], [0, 1], 'k')\n",
    "plt.plot([0, 1], [0, 0], 'k')\n",
    "plt.plot([0, 1], [1, 1], 'k')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((0, 1))\n",
    "plt.axis('equal')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У ROC-кривой в общем-то есть два определения.\n",
    "\n",
    "1) Вот у нас есть отсортированный по вероятности массив объектов. Нам нужно решить, где его разрезать на две части - все левые мы предскажем как класс 0, а правые как класс 1.\n",
    "\n",
    "Давайте для каждого возможного разреза просто посчитаемдве метрики и нарисуес график зависимости одной от другой:\n",
    "\n",
    "$$False\\space positive\\space rate = \\frac{FP}{FP + TN} = \\frac{FP}{size(0)}$$\n",
    "$$True\\space positive\\space rate = \\frac{TP}{TP + FN} = \\frac{TP}{size(1)}$$\n",
    "\n",
    "False positive rate - это доля предсказанных пульсаров среди реальных не-пульсаров.\n",
    "\n",
    "True positive rate - это доля предсказанных пульсаров среди реальных пульсаров.\n",
    "\n",
    "2) Наша кривая начинается в точке $(0, 0)$ и заканчивается в точке $(1, 1)$ (действительно, если мы все считаем не-пульсарами, то FPR = 0, TPR = 0, иначе FPR = 1, TPR = 1.\n",
    "\n",
    "Между ними она должна сделать несколько шагов вверх и вправо. Давайте просто идти слева направо по нашему и списку и каждый раз, когда попался объект класса 0, делать шаг вверх на $\\frac{1}{size(0)}$, а когда встретился объект класса 1, делать шаг вправо на $\\frac{1}{size(1)}$. Тогда мы в итоге обязательно придем из (0, 0) в (1, 1), и это получится ровно та же кривая.\n",
    "\n",
    "Действительно, каждый раз мы на самом деле просто перемещаем один объект из класса 0 в класс 1. Если его реальный класс равен 0, то TPR не изменился, а FPR увеличился на $\\frac{1}{size(0)}$. Если его реальный класс равен 1, то FPR не изменился, а TPR увеличился на $\\frac{1}{size(1)}$. Так что это то же самое."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кривая это хорошо, но нам бы хотелось числовую метрику, которая бы говорила, насколько хорош получившийся из вероятностей порядок. Для это обычно берут **площадь под этой кривой** (Areas Under Curve - AUC), её еще называют ROC-AUC.\n",
    "\n",
    "Она не больше, чем 1, и чем выше и левее эта кривая, тем лучше.\n",
    "\n",
    "Практически всегда ROC AUC > 0.5 (иначе это легко поправить - надо просто перевернть все вероятности).\n",
    "\n",
    "ROC AUC позволяет глубоко оценивать качество предсказанных вероятностей. Accuracy, Precision и Recall работали только с самими предсказаниями классов, и никак вероятности не затрагивали."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9748439516958035"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Небинарная классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы с вами рассматривали всё это время только задачу бинарной классификации, но что делать, когда классов болше, чем 2? На самом деле есть простой способ сводить любую классификацию к бинарной.\n",
    "\n",
    "Методика называется **One vs The Rest**. Давайте просто рассмотрим каждый класс как независимую бинарную классификацию, и будем предсказывать вероятности того, что этот элемент лежит в этом классе, или не лежит.\n",
    "\n",
    "Так про каждый класс мы получим вероятность, лежит ли в нем объект. Из них мы уже сможем выбрать лучший класс для этого объекта. А чтобы получить вероятности принадлежности каждому классу, эти числа еще нужно отнормировать, чтобы в сумме они давали 1.\n",
    "\n",
    "Давайте, например, рассмотрим датасет с циферками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "data = load_digits()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data['data']\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти фичи - это на самом деле яркости пикселей вот такой картинки 8x8. Каждый пиксель - это число от 0 до 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_digit(features):\n",
    "    plt.imshow(features.reshape(8, 8), cmap=plt.cm.gray, vmax=16, interpolation='nearest')\n",
    "\n",
    "draw_digit(X[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_digit(X[60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 178,\n",
       "         1: 182,\n",
       "         2: 177,\n",
       "         3: 183,\n",
       "         4: 181,\n",
       "         5: 182,\n",
       "         6: 181,\n",
       "         7: 179,\n",
       "         8: 174,\n",
       "         9: 180})"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['target']\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В логистической регрессии уже по умолчанию включен мод One vs The Rest и она работает для нескольких классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gleb/Desktop/Projects/tinkoff/tinkoff_ML_venv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/Gleb/Desktop/Projects/tinkoff/tinkoff_ML_venv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 3, 7, 2, 1, 5, 2, 5, 2, 1, 8, 4, 0, 4, 2, 3, 7, 8, 8, 4, 3,\n",
       "       9, 7, 5, 6, 3, 5, 6, 3, 4, 9, 1, 4, 4, 6, 9, 4, 7, 6, 6, 9, 1, 3,\n",
       "       6, 1, 3, 0, 6, 5, 5, 1, 9, 5, 6, 0, 9, 0, 0, 1, 0, 4, 5, 2, 4, 5,\n",
       "       7, 0, 7, 5, 9, 5, 5, 4, 7, 0, 4, 5, 5, 9, 9, 0, 2, 3, 8, 0, 6, 4,\n",
       "       4, 9, 1, 2, 8, 3, 5, 2, 9, 0, 4, 4, 4, 3, 5, 3, 1, 3, 5, 9, 4, 2,\n",
       "       7, 7, 4, 4, 1, 9, 2, 7, 8, 7, 2, 6, 9, 4, 0, 7, 2, 7, 5, 8, 7, 5,\n",
       "       7, 9, 0, 6, 6, 4, 2, 8, 0, 9, 4, 6, 9, 9, 6, 9, 0, 5, 5, 6, 6, 0,\n",
       "       6, 4, 3, 9, 3, 8, 7, 2, 9, 0, 6, 5, 3, 6, 5, 8, 9, 8, 4, 2, 1, 3,\n",
       "       7, 7, 2, 2, 3, 9, 8, 0, 3, 2, 2, 5, 6, 9, 9, 4, 1, 2, 4, 2, 3, 6,\n",
       "       4, 8, 5, 9, 5, 7, 8, 9, 4, 8, 1, 5, 4, 4, 9, 6, 1, 8, 6, 0, 4, 5,\n",
       "       2, 7, 1, 6, 4, 5, 6, 0, 3, 2, 3, 6, 7, 1, 5, 1, 4, 7, 6, 5, 8, 5,\n",
       "       5, 1, 5, 2, 8, 8, 9, 8, 7, 6, 2, 2, 2, 3, 4, 8, 8, 3, 6, 0, 9, 7,\n",
       "       7, 0, 1, 0, 4, 5, 8, 5, 3, 6, 0, 4, 1, 0, 0, 3, 6, 5, 9, 7, 3, 5,\n",
       "       5, 9, 9, 8, 5, 3, 3, 2, 0, 5, 8, 3, 4, 0, 2, 4, 6, 4, 3, 4, 5, 0,\n",
       "       5, 2, 1, 3, 1, 4, 1, 1, 7, 0, 1, 5, 2, 1, 2, 8, 7, 0, 6, 4, 8, 8,\n",
       "       5, 1, 8, 4, 5, 8, 7, 9, 8, 6, 0, 6, 2, 0, 7, 9, 1, 9, 5, 2, 7, 7,\n",
       "       1, 8, 7, 4, 3, 8, 3, 5])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "y_pred_log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict_proba теперь возвращает массив с вероятностями каждого из 3 классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.06549844e-05, 3.77759007e-07, 1.44110318e-11, ...,\n",
       "        4.43102255e-09, 3.69295370e-05, 9.73764724e-07],\n",
       "       [1.66657418e-06, 2.65576052e-10, 2.09550062e-12, ...,\n",
       "        5.05174578e-10, 2.25765932e-05, 9.84534835e-01],\n",
       "       [1.38336246e-13, 1.64772013e-08, 7.85166665e-08, ...,\n",
       "        4.34970782e-07, 9.47076544e-03, 7.93126604e-04],\n",
       "       ...,\n",
       "       [9.68507875e-06, 3.28329539e-05, 5.75867441e-05, ...,\n",
       "        2.25143481e-06, 9.99213231e-01, 3.21974934e-07],\n",
       "       [1.98566749e-07, 1.25304441e-08, 2.64753895e-04, ...,\n",
       "        8.09332195e-11, 1.71979751e-06, 1.38523487e-05],\n",
       "       [2.28354438e-07, 1.16973486e-04, 8.63243868e-11, ...,\n",
       "        1.83274335e-11, 3.10137089e-05, 6.38986956e-03]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba_log_reg = log_reg.predict_proba(X_test)\n",
    "y_pred_proba_log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот для KNN вообще нет разницы, два класса или больше: алгоритм работает ровно так же - выбирает самый популярный класс из $K$ соседей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 3, 7, 2, 1, 5, 2, 5, 2, 1, 9, 4, 0, 4, 2, 3, 7, 8, 8, 4, 3,\n",
       "       9, 7, 5, 6, 3, 5, 6, 3, 4, 9, 1, 4, 4, 6, 9, 4, 7, 6, 6, 9, 1, 3,\n",
       "       6, 1, 3, 0, 6, 5, 5, 1, 9, 5, 6, 0, 9, 0, 0, 1, 0, 4, 5, 2, 4, 5,\n",
       "       7, 0, 7, 5, 9, 9, 5, 4, 7, 0, 4, 5, 5, 9, 9, 0, 2, 3, 8, 0, 6, 4,\n",
       "       4, 9, 1, 2, 8, 3, 5, 2, 9, 0, 4, 4, 4, 3, 5, 3, 1, 3, 5, 9, 4, 2,\n",
       "       7, 7, 4, 4, 1, 9, 2, 7, 8, 7, 2, 6, 9, 4, 0, 7, 2, 7, 5, 8, 7, 5,\n",
       "       7, 9, 0, 6, 6, 4, 2, 8, 0, 9, 4, 6, 9, 9, 6, 9, 0, 3, 5, 6, 6, 0,\n",
       "       6, 4, 3, 9, 3, 4, 7, 2, 9, 0, 4, 5, 3, 6, 5, 9, 9, 8, 4, 2, 1, 3,\n",
       "       7, 7, 2, 2, 3, 9, 8, 0, 3, 2, 2, 5, 6, 9, 9, 4, 1, 5, 4, 2, 3, 6,\n",
       "       4, 8, 5, 9, 5, 7, 8, 9, 4, 8, 1, 5, 4, 4, 9, 6, 1, 8, 6, 0, 4, 5,\n",
       "       2, 7, 4, 6, 4, 5, 6, 0, 3, 2, 3, 6, 7, 1, 5, 1, 4, 7, 6, 8, 8, 5,\n",
       "       5, 1, 6, 2, 8, 8, 9, 5, 7, 6, 2, 2, 2, 3, 4, 8, 8, 3, 6, 0, 9, 7,\n",
       "       7, 0, 1, 0, 4, 5, 1, 5, 3, 6, 0, 4, 1, 0, 0, 3, 6, 5, 9, 7, 3, 5,\n",
       "       5, 9, 9, 8, 5, 3, 3, 2, 0, 5, 8, 3, 4, 0, 2, 4, 6, 4, 3, 4, 5, 0,\n",
       "       5, 2, 1, 3, 1, 4, 1, 1, 7, 0, 1, 5, 2, 1, 2, 8, 7, 0, 6, 4, 8, 8,\n",
       "       5, 1, 8, 4, 5, 8, 7, 9, 8, 6, 0, 6, 2, 0, 7, 9, 8, 9, 5, 2, 7, 7,\n",
       "       1, 8, 7, 4, 3, 8, 3, 5])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba_knn = knn.predict_proba(X_test)\n",
    "y_pred_proba_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9611111111111111\n",
      "0.9861111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred_log_reg))\n",
    "print(accuracy_score(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика Accuracy - одна из немногих, которая легко переносится с бинарной классификации на небинарную. Это все еще просто доля объектов с верно угаданным классами.\n",
    "\n",
    "Как мы видим, обе известные нам модели работают на цифрах очень и очень круто, учитывая что там 10 сбалансированных классов, а они угадывают больше 96%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот с другими метриками возникают проблемы - неочевидно как обобщить их на несколько классов. Обычно есть два способа это сделать.\n",
    "\n",
    "- macro - это аналог One vs The Rest, метрика просто считается для каждого класса независимо, а потом усредняется\n",
    "\n",
    "- micro - это более сложная вещь, здесь нужно рассмотреть каждую пару \"объект, класс\" как объекты, и как будто считать метрики на бинарной классификации в этой задаче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9605024983955005\n",
      "0.9879206496042758\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_test, y_pred_log_reg, average='macro'))\n",
    "print(precision_score(y_test, y_pred_knn, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9611111111111111\n",
      "0.9861111111111112\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_test, y_pred_log_reg, average='micro'))\n",
    "print(precision_score(y_test, y_pred_knn, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9624192637276927\n",
      "0.9878035043804756\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_test, y_pred_log_reg, average='macro'))\n",
    "print(recall_score(y_test, y_pred_knn, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9611111111111111\n",
      "0.9861111111111112\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_test, y_pred_log_reg, average='micro'))\n",
    "print(recall_score(y_test, y_pred_knn, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9609438803307118\n",
      "0.9877979367135244\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, y_pred_log_reg, average='macro'))\n",
    "print(f1_score(y_test, y_pred_knn, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9609438803307118\n",
      "0.9877979367135244\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, y_pred_log_reg, average='macro'))\n",
    "print(f1_score(y_test, y_pred_knn, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, на этом датасете везде получается одно и то же ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
